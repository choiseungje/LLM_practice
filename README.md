# Llama Fast API Server

![Screenshot](./res/image/screenshot.png)

## Installation

### FastAPI

#### Windows
```bash
pip install fastapi
```

#### macOS
```bash
pip3 install fastapi
```


### Llama-cpp-python

#### Windows + CUDA
```bash
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
```

#### Windows + CPU
```bash
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
```

#### macOS + Metal
```bash
pip3 install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/metal
```
